# -*- coding: utf-8 -*-

"""ramuda.
Script to deploy Lambda functions to AWS
"""

from __future__ import unicode_literals, print_function
import sys
import os
import shutil
import uuid
import time
from datetime import datetime, timedelta
import json
import logging

from botocore.exceptions import ClientError as ClientError
from clint.textui import colored

from gcdt.ramuda_utils import json2table, s3_upload, \
    lambda_exists, create_sha256, get_remote_code_hash, unit, \
    aggregate_datapoints, list_of_dict_equals, \
    create_aws_s3_arn, get_bucket_from_s3_arn, get_rule_name_from_event_arn, \
    build_filter_rules


log = logging.getLogger(__name__)
ALIAS_NAME = 'ACTIVE'
ENSURE_OPTIONS = ['absent', 'exists']


def _create_alias(awsclient, function_name, function_version,
                  alias_name=ALIAS_NAME):
    client_lambda = awsclient.get_client('lambda')
    response = client_lambda.create_alias(
        FunctionName=function_name,
        Name=alias_name,
        FunctionVersion=function_version,

    )
    return response['AliasArn']


def _update_alias(awsclient, function_name, function_version,
                  alias_name=ALIAS_NAME):
    client_lambda = awsclient.get_client('lambda')
    response = client_lambda.update_alias(
        FunctionName=function_name,
        Name=alias_name,
        FunctionVersion=function_version,

    )
    return response['AliasArn']


def _alias_exists(awsclient, function_name, alias_name):
    client_lambda = awsclient.get_client('lambda')
    try:
        client_lambda.get_alias(
            FunctionName=function_name,
            Name=alias_name
        )
        return True
    except Exception:
        return False


def _get_alias_version(awsclient, function_name, alias_name):
    # this is used for testing - it returns the version
    client_lambda = awsclient.get_client('lambda')
    try:
        response = client_lambda.get_alias(
            FunctionName=function_name,
            Name=alias_name
        )
        return response['FunctionVersion']
    except Exception:
        return


def _get_version_from_response(data):
    version = data['Version']
    return int(version) if version.isdigit() else 0


def _get_previous_version(awsclient, function_name, alias_name):
    client_lambda = awsclient.get_client('lambda')
    response = client_lambda.get_alias(
        FunctionName=function_name,
        Name=alias_name
    )
    current_version = response['FunctionVersion']
    if current_version != '$LATEST':
        return str(int(current_version) - 1)

    max_version = 0
    marker = None
    request_more_versions = True
    while request_more_versions:
        kwargs = {'Marker': marker} if marker else {}
        response = client_lambda.list_versions_by_function(
            FunctionName=function_name, **kwargs)
        if 'Marker' not in response:
            request_more_versions = False
        else:
            marker = response['Marker']
        versions = map(_get_version_from_response, response['Versions'])
        versions.append(max_version)
        max_version = max(versions)
    return str(max(0, max_version - 1))


def _deploy_alias(awsclient, function_name, function_version,
                  alias_name=ALIAS_NAME):
    if _alias_exists(awsclient, function_name, alias_name):
        _update_alias(awsclient, function_name, function_version, alias_name)
    else:
        _create_alias(awsclient, function_name, function_version, alias_name)


def _lambda_add_time_schedule_event_source(awsclient, rule_name,
                                           rule_description,
                                           schedule_expression, lambda_arn):
    client_event = awsclient.get_client('events')
    client_event.put_rule(
        Name=rule_name,
        ScheduleExpression=schedule_expression,
        Description=rule_description,
    )
    rule_response = client_event.describe_rule(Name=rule_name)
    if rule_response is not None:
        client_event.put_targets(
            Rule=rule_name,
            Targets=[
                {
                    'Id': '1',
                    'Arn': lambda_arn,
                },
            ]
        )

    return rule_response['Arn']


def _lambda_add_invoke_permission(awsclient, function_name,
                                  source_principal,
                                  source_arn, alias_name=ALIAS_NAME):
    # https://www.getoto.net/noise/2015/08/20/better-together-amazon-ecs-and-aws-lambda/
    # http://docs.aws.amazon.com/cli/latest/reference/lambda/add-permission.html
    client_lambda = awsclient.get_client('lambda')
    response = client_lambda.add_permission(
        FunctionName=function_name,
        StatementId=str(uuid.uuid1()),
        Action='lambda:InvokeFunction',
        Principal=source_principal,
        SourceArn=source_arn,
        Qualifier=alias_name
    )
    return response


def _lambda_add_s3_event_source(awsclient, arn, event, bucket, prefix,
                                suffix):
    """Use only prefix OR suffix

    :param arn:
    :param event:
    :param bucket:
    :param prefix:
    :param suffix:
    :return:
    """
    json_data = {
        'LambdaFunctionConfigurations': [{
            'LambdaFunctionArn': arn,
            'Id': str(uuid.uuid1()),
            'Events': [event]
        }]
    }

    filter_rules = build_filter_rules(prefix, suffix)

    json_data['LambdaFunctionConfigurations'][0].update({
        'Filter': {
            'Key': {
                'FilterRules': filter_rules
            }
        }
    })
    # http://docs.aws.amazon.com/cli/latest/reference/s3api/put-bucket-notification-configuration.html
    # http://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html
    client_s3 = awsclient.get_client('s3')

    bucket_configurations = client_s3.get_bucket_notification_configuration(
        Bucket=bucket)
    bucket_configurations.pop('ResponseMetadata')

    if 'LambdaFunctionConfigurations' in bucket_configurations:
        bucket_configurations['LambdaFunctionConfigurations'].append(
            json_data['LambdaFunctionConfigurations'][0]
        )
    else:
        bucket_configurations['LambdaFunctionConfigurations'] = json_data[
            'LambdaFunctionConfigurations']

    response = client_s3.put_bucket_notification_configuration(
        Bucket=bucket,
        NotificationConfiguration=bucket_configurations
    )
    # TODO don't return a table, but success state
    return json2table(response)


def list_functions(awsclient):
    """List the deployed lambda functions and print configuration.

    :return: exit_code
    """
    client_lambda = awsclient.get_client('lambda')
    response = client_lambda.list_functions()
    for function in response['Functions']:
        print(function['FunctionName'])
        print('\t' 'Memory: ' + str(function['MemorySize']))
        print('\t' 'Timeout: ' + str(function['Timeout']))
        print('\t' 'Role: ' + str(function['Role']))
        print('\t' 'Current Version: ' + str(function['Version']))
        print('\t' 'Last Modified: ' + str(function['LastModified']))
        print('\t' 'CodeSha256: ' + str(function['CodeSha256']))

        print('\n')
    return 0


def deploy_lambda(awsclient, function_name, role, handler_filename,
                  handler_function,
                  folders, description, timeout, memory, subnet_ids=None,
                  security_groups=None, artifact_bucket=None,
                  zipfile=None,
                  fail_deployment_on_unsuccessful_ping=False,
                  runtime='python2.7', settings=None):
    """Create or update a lambda function.

    :param awsclient:
    :param function_name:
    :param role:
    :param handler_filename:
    :param handler_function:
    :param folders:
    :param description:
    :param timeout:
    :param memory:
    :param subnet_ids:
    :param security_groups:
    :param artifact_bucket:
    :param zipfile:
    :return: exit_code
    """
    if lambda_exists(awsclient, function_name):
        function_version = _update_lambda(awsclient, function_name,
                                          handler_filename,
                                          handler_function, folders, role,
                                          description, timeout, memory,
                                          subnet_ids, security_groups,
                                          artifact_bucket=artifact_bucket,
                                          zipfile=zipfile
                                        )
    else:
        if not zipfile:
            return 1
        log.info('buffer size: %0.2f MB' % float(len(zipfile) / 1000000.0))
        function_version = _create_lambda(awsclient, function_name, role,
                                          handler_filename, handler_function,
                                          folders, description, timeout,
                                          memory, subnet_ids, security_groups,
                                          artifact_bucket, zipfile,
                                          runtime=runtime)
    pong = ping(awsclient, function_name, version=function_version)
    if 'alive' in pong:
        print(colored.green('Great you\'re already accepting a ping ' +
                            'in your Lambda function'))
    elif fail_deployment_on_unsuccessful_ping and not 'alive' in pong:
        print(colored.red('Pinging your lambda function failed'))
        # we do not deploy alias and fail command
        return 1
    else:
        print(colored.red('Please consider adding a reaction to a ' +
                          'ping event to your lambda function'))
    _deploy_alias(awsclient, function_name, function_version)
    return 0


def _create_lambda(awsclient, function_name, role, handler_filename,
                   handler_function,
                   folders, description, timeout, memory,
                   subnet_ids=None, security_groups=None,
                   artifact_bucket=None, zipfile=None, runtime='python2.7'):
    log.debug('create lambda function: %s' % function_name)
    # move to caller!
    # _install_dependencies_with_pip('requirements.txt', './vendored')
    client_lambda = awsclient.get_client('lambda')
    # print ('creating function %s with role %s handler %s folders %s timeout %s memory %s') % (
    # function_name, role, handler_filename, str(folders), str(timeout), str(memory))

    if not artifact_bucket:
        log.debug('create without artifact bucket...')
        response = client_lambda.create_function(
            FunctionName=function_name,
            Runtime=runtime,
            Role=role,
            Handler=handler_function,
            Code={
                'ZipFile': zipfile
            },
            Description=description,
            Timeout=int(timeout),
            MemorySize=int(memory),
            Publish=True
        )
    elif artifact_bucket and zipfile:
        log.debug('create with artifact bucket...')
        # print 'uploading bundle to s3'
        dest_key, e_tag, version_id = \
            s3_upload(awsclient, artifact_bucket, zipfile, function_name)
        # print dest_key, e_tag, version_id
        response = client_lambda.create_function(
            FunctionName=function_name,
            Runtime=runtime,
            Role=role,
            Handler=handler_function,
            Code={
                'S3Bucket': artifact_bucket,
                'S3Key': dest_key,
                'S3ObjectVersion': version_id
            },
            Description=description,
            Timeout=int(timeout),
            MemorySize=int(memory),
            Publish=True
        )
    else:
        log.debug('no zipfile and no artifact_bucket -> nothing to do!')
        # no zipfile and no artifact_bucket -> nothing to do!
        return

    function_version = response['Version']
    print(json2table(response))
    # FIXME: 23.08.2016 WHY update configuration after create?
    # timing issue:
    # http://jenkins.dev.dp.glomex.cloud/job/packages/job/gcdt_pull_request/32/console
    #       1) we need to wait till the function is available for update
    #          is there a better way than sleep?
    time.sleep(15)
    #       2) I believe this was implemented as shortcut to set subnet, and sg
    #          a way better way is to set this is using the using VPCConfig argument!
    _update_lambda_configuration(
        awsclient, function_name, role, handler_function, description,
        timeout, memory, subnet_ids, security_groups
    )
    return function_version


def _update_lambda(awsclient, function_name, handler_filename,
                   handler_function, folders,
                   role, description, timeout, memory, subnet_ids=None,
                   security_groups=None, artifact_bucket=None,
                   zipfile=None
                   ):
    log.debug('update lambda function: %s' % function_name)
    _update_lambda_function_code(awsclient, function_name,
                                 artifact_bucket=artifact_bucket,
                                 zipfile=zipfile
    )
    function_version = \
        _update_lambda_configuration(
            awsclient, function_name, role, handler_function,
            description, timeout, memory, subnet_ids, security_groups
        )
    return function_version


def bundle_lambda(zipfile):
    """Write zipfile contents to file.

    :param zipfile:
    :return: exit_code
    """
    # TODO have 'bundle.zip' as default config
    if not zipfile:
        return 1
    with open('bundle.zip', 'wb') as zfile:
        zfile.write(zipfile)
    print('Finished - a bundle.zip is waiting for you...')
    return 0


def _update_lambda_function_code(
        awsclient, function_name,
        artifact_bucket=None,
        zipfile=None
        ):
    client_lambda = awsclient.get_client('lambda')
    if not zipfile:
        return 1
    local_hash = create_sha256(zipfile)
    # print ('getting remote hash')

    # print local_hash
    remote_hash = get_remote_code_hash(awsclient, function_name)
    # print remote_hash
    if local_hash == remote_hash:
        print('Code hasn\'t changed - won\'t upload code bundle')
    else:
        if not artifact_bucket:
            log.info('no stack bucket found')
            response = client_lambda.update_function_code(
                FunctionName=function_name,
                ZipFile=zipfile,
                Publish=True
            )
        else:
            # reuse the zipfile we already created!
            dest_key, e_tag, version_id = \
                s3_upload(awsclient, artifact_bucket, zipfile, function_name)
            # print dest_key, e_tag, version_id
            response = client_lambda.update_function_code(
                FunctionName=function_name,
                S3Bucket=artifact_bucket,
                S3Key=dest_key,
                S3ObjectVersion=version_id,
                Publish=True
            )
        print(json2table(response))
    return 0


def _update_lambda_configuration(awsclient, function_name, role,
                                 handler_function,
                                 description, timeout, memory, subnet_ids=None,
                                 security_groups=None):
    client_lambda = awsclient.get_client('lambda')
    if subnet_ids and security_groups:
        # print ('found vpc config')
        response = client_lambda.update_function_configuration(
            FunctionName=function_name,
            Role=role,
            Handler=handler_function,
            Description=description,
            Timeout=timeout,
            MemorySize=memory,
            VpcConfig={
                'SubnetIds': subnet_ids,
                'SecurityGroupIds': security_groups
            }
        )
        print(json2table(response))
    else:
        response = client_lambda.update_function_configuration(
            FunctionName=function_name,
            Role=role,
            Handler=handler_function,
            Description=description,
            Timeout=timeout,
            MemorySize=memory)

        print(json2table(response))
    function_version = response['Version']
    return function_version


def get_metrics(awsclient, name):
    """Print out cloudformation metrics for a lambda function.

    :param awsclient
    :param name: name of the lambda function
    :return: exit_code
    """
    metrics = ['Duration', 'Errors', 'Invocations', 'Throttles']
    client_cw = awsclient.get_client('cloudwatch')
    for metric in metrics:
        response = client_cw.get_metric_statistics(
            Namespace='AWS/Lambda',
            MetricName=metric,
            Dimensions=[
                {
                    'Name': 'FunctionName',
                    'Value': name
                },
            ],
            StartTime=datetime.now() + timedelta(days=-1),
            EndTime=datetime.now(),
            Period=3600,
            Statistics=[
                'Sum',
            ],
            Unit=unit(metric)
        )
        print('\t%s %s' % (metric,
                           repr(aggregate_datapoints(response['Datapoints']))))
    return 0


def rollback(awsclient, function_name, alias_name=ALIAS_NAME, version=None):
    """Rollback a lambda function to a given version.

    :param awsclient:
    :param function_name:
    :param alias_name:
    :param version:
    :return: exit_code
    """
    if version:
        print('rolling back to version {}'.format(version))
    else:
        print('rolling back to previous version')
        version = _get_previous_version(awsclient, function_name, alias_name)
        if version == '0':
            print('unable to find previous version of lambda function')
            return 1

        print('new version is %s' % str(version))

    _update_alias(awsclient, function_name, version, alias_name)
    return 0


def delete_lambda(awsclient, function_name, s3_event_sources=[],
                  time_event_sources=[]):
    # FIXME: mutable default arguments!
    """Delete a lambda function.

    :param awsclient:
    :param function_name:
    :param s3_event_sources:
    :param time_event_sources:
    :return: exit_code
    """
    unwire(awsclient, function_name, s3_event_sources=s3_event_sources,
           time_event_sources=time_event_sources,
           alias_name=ALIAS_NAME)
    client_lambda = awsclient.get_client('lambda')
    response = client_lambda.delete_function(FunctionName=function_name)

    # TODO remove event source first and maybe also needed for permissions
    print(json2table(response))
    return 0


def info(awsclient, function_name, s3_event_sources=None,
         time_event_sources=None, alias_name=ALIAS_NAME):
    if s3_event_sources is None:
        s3_event_sources = []
    if time_event_sources is None:
        time_event_sources = []
    if not lambda_exists(awsclient, function_name):
        print(colored.red('The function you try to display doesn\'t ' +
                          'exist... Bailing out...'))
        return 1

    client_lambda = awsclient.get_client('lambda')
    lambda_function = client_lambda.get_function(FunctionName=function_name)
    lambda_alias = client_lambda.get_alias(FunctionName=function_name,
                                           Name=alias_name)
    lambda_arn = lambda_alias['AliasArn']

    if lambda_function is not None:
        print(json2table(lambda_function['Configuration']).encode('utf-8'))
        print(json2table(lambda_alias).encode('utf-8'))
        print("\n### PERMISSIONS ###\n")

        try:
            result = client_lambda.get_policy(FunctionName=function_name,
                                              Qualifier=alias_name)

            policy = json.loads(result['Policy'])
            for statement in policy['Statement']:
                print('{} ({}) -> {}'.format(
                    statement['Condition']['ArnLike']['AWS:SourceArn'],
                    statement['Principal']['Service'],
                    statement['Resource']
                ))
        except ClientError as e:
            if e.response['Error']['Code'] == 'ResourceNotFoundException':
                print("No permissions found!")
            else:
                raise e

        print("\n### EVENT SOURCES ###\n")

        # S3 Events
        client_s3 = awsclient.get_client('s3')
        for s3_event_source in s3_event_sources:
            bucket_name = s3_event_source.get('bucket')
            print('- \tS3: %s' % bucket_name)
            bucket_notification = client_s3.get_bucket_notification(
                Bucket=bucket_name)
            filter_rules = build_filter_rules(
                s3_event_source.get('prefix', None),
                s3_event_source.get('suffix', None))
            response = client_s3.get_bucket_notification_configuration(
                Bucket=bucket_name)
            if 'LambdaFunctionConfigurations' in response:
                relevant_configs, irrelevant_configs = \
                    filter_bucket_notifications_with_arn(
                        response['LambdaFunctionConfigurations'],
                        lambda_arn, filter_rules
                    )
                if len(relevant_configs) > 0:
                    for config in relevant_configs:
                        print('\t\t{}:'.format(config['Events'][0]))
                        for rule in config['Filter']['Key']['FilterRules']:
                            print('\t\t{}: {}'.format(rule['Name'],
                                                      rule['Value']))
                else:
                    print('\tNot attached')

                    # TODO Beautify
                    # wrapper = TextWrapper(initial_indent='\t', subsequent_indent='\t')
                    # output = "\n".join(wrapper.wrap(json.dumps(config, indent=True)))
                    # print(json.dumps(config, indent=True))
            else:
                print('\tNot attached')

        # CloudWatch Event
        client_events = awsclient.get_client('events')
        for time_event in time_event_sources:
            rule_name = time_event.get('ruleName')
            print('- \tCloudWatch: %s' % rule_name)
            try:
                rule_response = client_events.describe_rule(Name=rule_name)
                target_list = client_events.list_targets_by_rule(
                    Rule=rule_name,
                )["Targets"]
                if target_list:
                    print("\t\tSchedule expression: {}".format(
                        rule_response['ScheduleExpression']))
                for target in target_list:
                    print(
                        '\t\tId: {} -> {}'.format(target['Id'], target['Arn']))
            except ClientError as e:
                if e.response['Error']['Code'] == 'ResourceNotFoundException':
                    print('\tNot attached!')
                else:
                    raise e


def filter_bucket_notifications_with_arn(lambda_function_configurations,
                                         lambda_arn, filter_rules=False):
    matching_notifications = []
    not_matching_notifications = []
    for notification in lambda_function_configurations:
        if notification["LambdaFunctionArn"] == lambda_arn:
            if filter_rules:
                existing_filter = notification['Filter']['Key']['FilterRules']
                if list_of_dict_equals(filter_rules, existing_filter):
                    matching_notifications.append(notification)
                else:
                    not_matching_notifications.append(notification)
            else:
                matching_notifications.append(notification)
        else:
            not_matching_notifications.append(notification)
    return matching_notifications, not_matching_notifications


def _ensure_s3_event(awsclient, s3_event_source, function_name, alias_name,
                     target_lambda_arn, ensure="exists"):
    if ensure not in ENSURE_OPTIONS:
        print("{} is invalid ensure option, should be {}".format(ensure,
                                                                 ENSURE_OPTIONS))

    client_s3 = awsclient.get_client('s3')

    bucket_name = s3_event_source.get('bucket')
    event_type = s3_event_source.get('type')
    prefix = s3_event_source.get('prefix', None)
    suffix = s3_event_source.get('suffix', None)

    rule_exists = False
    filter_rules = build_filter_rules(prefix, suffix)

    bucket_configurations = client_s3.get_bucket_notification_configuration(
        Bucket=bucket_name)
    bucket_configurations.pop('ResponseMetadata')
    matching_notifications, not_matching_notifications = filter_bucket_notifications_with_arn(
        bucket_configurations.get('LambdaFunctionConfigurations', []),
        target_lambda_arn, filter_rules)

    for config in matching_notifications:
        if config['Events'][0] == event_type:
            if filter_rules:
                if list_of_dict_equals(filter_rules,
                                       config['Filter']['Key']['FilterRules']):
                    rule_exists = True
            else:
                rule_exists = True
    # permissions_exists
    permission_exists = False
    if rule_exists:
        policies = _get_lambda_policies(awsclient, function_name, alias_name)
        if policies:
            for statement in policies['Statement']:
                if statement['Principal']['Service'] == 's3.amazonaws.com':
                    permission_bucket = get_bucket_from_s3_arn(
                        statement['Condition']['ArnLike']['AWS:SourceArn'])
                    if permission_bucket == bucket_name:
                        permission_exists = statement['Sid']
                        break

    if not rule_exists and not permission_exists:
        if ensure == "exists":
            print(colored.magenta(
                "\tWiring rule {}: {}".format(bucket_name, event_type)))
            for rule in filter_rules:
                print(colored.magenta(
                    '\t\t{}: {}'.format(rule['Name'], rule['Value'])))
            _wire_s3_to_lambda(awsclient, s3_event_source, function_name,
                               target_lambda_arn)
        elif ensure == "absent":
            return 0
    if rule_exists and permission_exists:
        if ensure == "absent":
            print(colored.magenta(
                "\tRemoving rule {}: {}".format(bucket_name, event_type)))
            for rule in filter_rules:
                print(colored.magenta(
                    '\t\t{}: {}'.format(rule['Name'], rule['Value'])))
            _remove_permission(awsclient, function_name, permission_exists, alias_name)
            _remove_events_from_s3_bucket(awsclient, bucket_name, target_lambda_arn,
                                          filter_rules)


def _ensure_cloudwatch_event(awsclient, time_event, function_name,
                             alias_name, lambda_arn, ensure='exists'):
    if not ensure in ENSURE_OPTIONS:
        print("{} is invalid ensure option, should be {}".format(ensure,
                                                                 ENSURE_OPTIONS))
        # TODO unbelievable: another sys.exit in library code!!!
        sys.exit(1)
    rule_name = time_event.get('ruleName')
    rule_description = time_event.get('ruleDescription')
    schedule_expression = time_event.get('scheduleExpression')
    client_event = awsclient.get_client('events')

    rule_exists = False
    schedule_expression_match = False
    not_matching_schedule_expression = None
    try:
        rule_response = client_event.describe_rule(Name=rule_name)
        rule_exists = True
        if rule_response['ScheduleExpression'] == schedule_expression:
            schedule_expression_match = True
        else:
            not_matching_schedule_expression = rule_response[
                'ScheduleExpression']
    except ClientError as e:
        if e.response['Error']['Code'] == 'ResourceNotFoundException':
            pass
        else:
            raise e

    permission_exists = False
    if rule_exists:
        policies = _get_lambda_policies(awsclient, function_name, alias_name)
        if policies:
            for statement in policies['Statement']:
                if statement['Principal']['Service'] == 'events.amazonaws.com':
                    event_source_arn = get_rule_name_from_event_arn(
                        statement['Condition']['ArnLike']['AWS:SourceArn'])
                    if rule_name == event_source_arn:
                        permission_exists = statement['Sid']
                        break

    if not rule_exists and not permission_exists:
        if ensure == 'exists':
            print(colored.magenta(
                "\tWiring Cloudwatch event {}\n\t\t{}".format(rule_name,
                                                              schedule_expression)))
            rule_arn = _lambda_add_time_schedule_event_source(
                awsclient, rule_name, rule_description, schedule_expression,
                lambda_arn)
            _lambda_add_invoke_permission(
                awsclient, function_name, 'events.amazonaws.com', rule_arn)
        elif ensure == 'absent':
            return 0
    if rule_exists and permission_exists:
        if ensure == 'exists':
            if schedule_expression_match:
                return 0
            else:
                print(colored.magenta(
                    "\t Updating Cloudwatch event {}\n\t\tOld: {}\n\t\tTo: {}".format(
                        rule_name,
                        not_matching_schedule_expression,
                        schedule_expression)))
                rule_arn = _lambda_add_time_schedule_event_source(
                    awsclient, rule_name, rule_description,
                    schedule_expression, lambda_arn)
        if ensure == 'absent':
            print(colored.magenta("\tRemoving rule {}\n\t\t{}".format(rule_name,
                                                                      schedule_expression)))
            _remove_permission(awsclient, function_name, statement['Sid'],
                               alias_name)
            _remove_cloudwatch_rule_event(awsclient, rule_name, lambda_arn)


def _wire_s3_to_lambda(awsclient, s3_event_source, function_name,
                       target_lambda_arn):
    bucket_name = s3_event_source.get('bucket')
    event_type = s3_event_source.get('type')
    prefix = s3_event_source.get('prefix', None)
    suffix = s3_event_source.get('suffix', None)
    s3_arn = create_aws_s3_arn(bucket_name)

    _lambda_add_invoke_permission(awsclient, function_name,
                                  's3.amazonaws.com', s3_arn)
    _lambda_add_s3_event_source(awsclient, target_lambda_arn, event_type,
                                bucket_name, prefix, suffix)


def wire(awsclient, function_name, s3_event_sources=None,
         time_event_sources=None,
         alias_name=ALIAS_NAME):
    """Wiring a lambda function to events.

    :param awsclient:
    :param function_name:
    :param s3_event_sources:
    :param time_event_sources:
    :param alias_name:
    :return: exit_code
    """
    if not lambda_exists(awsclient, function_name):
        print(colored.red('The function you try to wire up doesn\'t ' +
                          'exist... Bailing out...'))
        return 1
    client_lambda = awsclient.get_client('lambda')
    lambda_function = client_lambda.get_function(FunctionName=function_name)
    lambda_arn = client_lambda.get_alias(FunctionName=function_name,
                                         Name=alias_name)['AliasArn']
    print('wiring lambda_arn %s ...' % lambda_arn)

    if lambda_function is not None:
        s3_events_ensure_exists, s3_events_ensure_absent = filter_events_ensure(
            s3_event_sources)
        cloudwatch_events_ensure_exists, cloudwatch_events_ensure_absent = \
            filter_events_ensure(time_event_sources)

        for s3_event_source in s3_events_ensure_absent:
            _ensure_s3_event(awsclient, s3_event_source, function_name,
                             alias_name, lambda_arn, s3_event_source['ensure'])
        for s3_event_source in s3_events_ensure_exists:
            _ensure_s3_event(awsclient, s3_event_source, function_name,
                             alias_name, lambda_arn, s3_event_source['ensure'])

        for time_event in cloudwatch_events_ensure_absent:
            _ensure_cloudwatch_event(awsclient, time_event, function_name,
                                     alias_name, lambda_arn,
                                     time_event['ensure'])
        for time_event in cloudwatch_events_ensure_exists:
            _ensure_cloudwatch_event(awsclient, time_event, function_name,
                                     alias_name, lambda_arn,
                                     time_event['ensure'])
    return 0


def filter_events_ensure(event_sources):
    events_ensure_exists = []
    events_ensure_absent = []
    for event in event_sources:
        if 'ensure' in event:
            if event['ensure'] == 'exists':
                events_ensure_exists.append(event)
            elif event['ensure'] == 'absent':
                events_ensure_absent.append(event)
            else:
                print(colored.red(
                    'Ensure must be one of {}, currently set to {}'.format(
                        ENSURE_OPTIONS, event['ensure'])))
                # FIXME exit in lib code!
                # TODO: make sure it has a test!
                # TODO unbelievable: another sys.exit in library code!!!
                sys.exit(1)
        else:
            event['ensure'] = 'exists'
            events_ensure_exists.append(event)
    return events_ensure_exists, events_ensure_absent


def _get_lambda_policies(awsclient, function_name, alias_name):
    client_lambda = awsclient.get_client('lambda')
    policies = None
    try:
        result = client_lambda.get_policy(FunctionName=function_name,
                                          Qualifier=alias_name)
        policies = json.loads(result['Policy'])
    except ClientError as e:
        if e.response['Error']['Code'] == 'ResourceNotFoundException':
            print(colored.red("Permission policies not found"))
        else:
            raise e
    return policies


def unwire(awsclient, function_name, s3_event_sources=None,
           time_event_sources=None,
           alias_name=ALIAS_NAME):
    """Unwire an event from a lambda function.

    :param awsclient:
    :param function_name:
    :param s3_event_sources:
    :param time_event_sources:
    :param alias_name:
    :return: exit_code
    """
    if not lambda_exists(awsclient, function_name):
        print(colored.red('The function you try to wire up doesn\'t ' +
                          'exist... Bailing out...'))
        return 1

    client_lambda = awsclient.get_client('lambda')
    lambda_function = client_lambda.get_function(FunctionName=function_name)
    lambda_arn = client_lambda.get_alias(FunctionName=function_name,
                                         Name=alias_name)['AliasArn']
    print('UN-wiring lambda_arn %s ' % lambda_arn)
    policies = None
    try:
        result = client_lambda.get_policy(FunctionName=function_name,
                                          Qualifier=alias_name)
        policies = json.loads(result['Policy'])
    except ClientError as e:
        if e.response['Error']['Code'] == 'ResourceNotFoundException':
            print("Permission policies not found")
        else:
            raise e

    if lambda_function is not None:
        #### S3 Events
        # for every permission - delete it and corresponding rule (if exists)
        if policies:
            for statement in policies['Statement']:
                if statement['Principal']['Service'] == 's3.amazonaws.com':
                    source_bucket = get_bucket_from_s3_arn(
                        statement['Condition']['ArnLike']['AWS:SourceArn'])
                    print('\tRemoving S3 permission {} invoking {}'.format(
                        source_bucket, lambda_arn))
                    _remove_permission(awsclient, function_name,
                                       statement['Sid'], alias_name)
                    print('\tRemoving All S3 events {} invoking {}'.format(
                        source_bucket, lambda_arn))
                    _remove_events_from_s3_bucket(awsclient, source_bucket,
                                                  lambda_arn)

        # Case: s3 events without permissions active "safety measure"
        for s3_event_source in s3_event_sources:
            bucket_name = s3_event_source.get('bucket')
            _remove_events_from_s3_bucket(awsclient, bucket_name, lambda_arn)

        #### CloudWatch Events
        # for every permission - delete it and corresponding rule (if exists)
        if policies:
            for statement in policies['Statement']:
                if statement['Principal']['Service'] == 'events.amazonaws.com':
                    rule_name = get_rule_name_from_event_arn(
                        statement['Condition']['ArnLike']['AWS:SourceArn'])
                    print(
                        '\tRemoving Cloudwatch permission {} invoking {}'.format(
                            rule_name, lambda_arn))
                    _remove_permission(awsclient, function_name,
                                       statement['Sid'], alias_name)
                    print('\tRemoving Cloudwatch rule {} invoking {}'.format(
                        rule_name, lambda_arn))
                    _remove_cloudwatch_rule_event(awsclient, rule_name,
                                                  lambda_arn)
        # Case: rules without permissions active, "safety measure"
        for time_event in time_event_sources:
            rule_name = time_event.get('ruleName')
            _remove_cloudwatch_rule_event(awsclient, rule_name, lambda_arn)

    return 0


def _remove_cloudwatch_rule_event(awsclient, rule_name, target_lambda_arn):
    client_event = awsclient.get_client('events')
    try:
        target_list = client_event.list_targets_by_rule(
            Rule=rule_name,
        )
    except ClientError as e:
        if e.response['Error']['Code'] == 'ResourceNotFoundException':
            return
        else:
            raise e
    target_id_list = []

    for target in target_list['Targets']:
        if target['Arn'] == target_lambda_arn:
            target_id_list += [target['Id']]
    # remove targets
    if target_id_list:
        client_event.remove_targets(
            Rule=rule_name,
            Ids=target_id_list,
        )
    # Delete rule only if all targets were associated with target_arn (i.e. only target target_arn function)
    if len(target_id_list) == len(target_list['Targets']) or (
                not target_id_list and not target_list):
        client_event.delete_rule(
            Name=rule_name
        )


def _remove_events_from_s3_bucket(awsclient, bucket_name, target_lambda_arn,
                                  filter_rule=False):
    client_s3 = awsclient.get_client('s3')
    bucket_configurations = client_s3.get_bucket_notification_configuration(
        Bucket=bucket_name)
    bucket_configurations.pop('ResponseMetadata')
    matching_notifications, not_matching_notifications = \
        filter_bucket_notifications_with_arn(
            bucket_configurations.get('LambdaFunctionConfigurations', []),
            target_lambda_arn, filter_rule
        )
    if not_matching_notifications:
        bucket_configurations[
            'LambdaFunctionConfigurations'] = not_matching_notifications
    else:
        if 'LambdaFunctionConfigurations' in bucket_configurations:
            bucket_configurations.pop('LambdaFunctionConfigurations')

    response = client_s3.put_bucket_notification_configuration(
        Bucket=bucket_name,
        NotificationConfiguration=bucket_configurations
    )


def _remove_permission(awsclient, function_name, statement_id, qualifier):
    client_lambda = awsclient.get_client('lambda')
    response_remove = client_lambda.remove_permission(
        FunctionName=function_name,
        StatementId=statement_id,
        Qualifier=qualifier
    )


def cleanup_bundle():
    """Deletes files used for creating bundle.
        * vendored/*
        * bundle.zip
    """
    paths = ['./vendored', './bundle.zip']
    for path in paths:
        if os.path.exists(path):
            log.debug("Deleting %s..." % path)
            if os.path.isdir(path):
                shutil.rmtree(path)
            else:
                os.remove(path)


def ping(awsclient, function_name, alias_name=ALIAS_NAME, version=None):
    """Send a ping request to a lambda function.

    :param awsclient:
    :param function_name:
    :param alias_name:
    :param version:
    :return: ping response payload
    """
    client_lambda = awsclient.get_client('lambda')
    payload = '{"ramuda_action": "ping"}'  # default to ping event

    if version:
        response = client_lambda.invoke(
            FunctionName=function_name,
            InvocationType='RequestResponse',
            Payload=payload,
            Qualifier=version
        )
    else:
        response = client_lambda.invoke(
            FunctionName=function_name,
            InvocationType='RequestResponse',
            Payload=payload,
            Qualifier=alias_name
        )

    results = response['Payload'].read()  # payload is a 'StreamingBody'
    return results
